## เปรียบเทียบผลลัพธ์จากการทดลองด้วย Hidden layers จำนวน 1 layers

![image](https://user-images.githubusercontent.com/87576892/152378755-2f06a96c-ec56-4d3a-a9a9-e41394123fb1.png)

•	เมื่อดูจาก AUC พบว่าผลการทดสอบที่ดีที่สุดได้ค่า AUC = 0.9827 โดยมีทั้งหมด 512 batch size, 25 epoch ใช้ learning rate 0.001 มีจำนวน node = 1 ใช้วิธี ADAM ในการ Optimize และใช้เวลาในการรันทั้งหมด 45.5192 วินาที 

•	Epoch: จากผลการทดลองพบว่าการTrain ด้วยจำนวน Epoch ที่ 5, 10 และ 15 ให้ผลลัพธ์ค่า AUC เฉลี่ยที่ไม่แตกต่างกันมาก แม้ว่าจำนวน 25 Epoch จะทำให้ได้ AUC เฉลี่ยสูงสุดที่ 0.943558333 และจำนวน 15 Epoch จะได้ค่า Loss เฉลี่ยน้อยที่สุดที่ 0.1135383 

•	Learning rate: จากผลการทดลองพบว่าการ Train ด้วย Learning rate เท่ากับ 0.005 สามาถทำค่าเฉลี่ย AUC และเวลาการ Train ได้ดีกว่าการTrain ด้วย Learning rate เท่ากับ 0.001 เล็กน้อย 

•	Optimizer: จากผลการทดลองพบว่าการใช้ Optimizer เป็น sgd ได้ผลเฉลี่ยทั้ง AUC และ loss ดีกว่าการใช้ Optimizer เป็น adam ค่อนข้างมาก โดย sgd ได้ AUC เฉลี่ย 0.934502963 และ Loss เฉลี่ย 0.11341467 ในขณะที่ adam ได้ Loss เฉลี่ยสูงถึง 0.336807 และได้ AUC เฉลี่ยเพียง 0.922517568 เท่านั้น

•	Num_node: จากผลการทดลอง พบว่าจำนวน Node ที่ 26 ให้ค่าเฉลี่ย AUC ที่สูงที่สุดที่ 0.971134167 ในขณะที่จำนวน 1 Node ให้ค่า AUC ที่ต่ำที่สุด

•	Activation: จากผลการทดลองพบว่า การใช้ Sigmoid ให้ค่าเฉลี่ย AUC สูงที่สุดที่ 0.970262202 แต่มีค่า average loss ต่ำกว่าการใช้ Relu ในขณะที่ running times สูงกว่าเล็กน้อย
